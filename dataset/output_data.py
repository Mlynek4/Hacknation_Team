import pandas as pd
import random
import re
from typing import List, Tuple, Dict

# --- Konfiguracja plik√≥w ---
VALUES_FILE = "anonymizer_values_55k.csv"
TEMPLATES_FILE = "szablony_zdan.csv"
OUTPUT_CONLL_FILE = "output_data.txt"

# üöÄ NOWA ZMIENNA KONTROLNA 
# Ustawia, ile razy ka≈ºdy szablon (zdanie) ma zostaƒá u≈ºyty do generowania unikatowych rekord√≥w.
# Przyk≈Çady:
# 1. Je≈õli masz 26 szablon√≥w i ustawisz 30, otrzymasz 780 rekord√≥w (26 * 30).
# 2. Je≈õli masz 50 szablon√≥w i ustawisz 10, otrzymasz 500 rekord√≥w.
RECORDS_PER_TEMPLATE = 50 # TUTAJ KONTROLUJESZ LICZBƒò GENEROWANYCH ZDA≈É

# Regex do ekstrakcji placeholder√≥w (np. [name])
PLACEHOLDER_RE = re.compile(r"\[([^\]]+)\]")

# --- Funkcje pomocnicze ---

def simple_tokenize(text: str) -> List[str]:
    """
    Prosta tokenizacja na potrzeby CoNLL.
    Rozdziela po spacji, ale zachowuje znaki interpunkcyjne jako oddzielne tokeny.
    """
    # Znajduje ciƒÖgi znak√≥w (s≈Çowa, cyfry, z≈Ço≈ºone ciƒÖgi jak e-maile/numery) ORAZ pojedyncze znaki interpunkcyjne.
    tokens = re.findall(r"\w[\w\.\-\+@]*|\S", text)
    return tokens

def load_data():
    """≈Åaduje warto≈õci i szablony."""
    try:
        df_vals = pd.read_csv(VALUES_FILE)
        values_by_cat = df_vals.groupby("category")["value"].apply(list).to_dict()
        
        df_templates = pd.read_csv(TEMPLATES_FILE)
        templates = df_templates["template"].tolist()
        
        return values_by_cat, templates
    except FileNotFoundError as e:
        print(f"B≈ÇƒÖd: Nie znaleziono pliku: {e.filename}")
        return None, None
    except Exception as e:
        print(f"WystƒÖpi≈Ç b≈ÇƒÖd podczas ≈Çadowania danych: {e}")
        return None, None

def tokenize_and_tag(
    template_part: str, 
    value: str = None, 
    category: str = None
) -> List[Tuple[str, str]]:
    """
    Tokenizuje fragment tekstu i przypisuje tagi BIO.
    Je≈õli podana jest warto≈õƒá i kategoria, fragment tekstu jest traktowany jako encja.
    """
    if value and category:
        # Tokenizujemy wstawionƒÖ warto≈õƒá
        entity_tokens = simple_tokenize(value)
        tagged_tokens = []
        tag_prefix = category.upper()
        
        # Przypisujemy tagi B- i I-
        for i, token in enumerate(entity_tokens):
            tag = f"B-{tag_prefix}" if i == 0 else f"I-{tag_prefix}"
            tagged_tokens.append((token, tag))
        
        return tagged_tokens

    else:
        # Tokenizujemy standardowy tekst szablonu (bez encji)
        untagged_tokens = simple_tokenize(template_part)
        return [(token, "O") for token in untagged_tokens]

def generate_conll(templates: List[str], values_by_cat: Dict[str, List[str]]) -> List[str]:
    """
    Generuje dane CoNLL przez przetwarzanie szablon√≥w i wstawianie warto≈õci.
    """
    all_conll_lines = []
    
    for template in templates:
        # Znajdujemy wszystkie placeholdery w szablonie
        placeholders = PLACEHOLDER_RE.findall(template)
        
        # Wype≈Çniamy warto≈õciami i jednocze≈õnie ≈õledzimy granice
        parts = PLACEHOLDER_RE.split(template)
        
        current_conll_entry = []
        
        for i, part in enumerate(parts):
            if i % 2 == 0:
                # To jest tekst, kt√≥ry NIE jest placeholderem (czƒô≈õƒá O-tagowana)
                if part:
                    current_conll_entry.extend(tokenize_and_tag(part))
            else:
                # To jest nazwa placeholdera (np. 'phone', 'name')
                category = part
                
                # Wylosuj warto≈õƒá
                # U≈ºywamy .get() i listy awaryjnej, aby obs≈Çu≈ºyƒá brakujƒÖce kategorie (MISSING-...)
                value = random.choice(values_by_cat.get(category, [f"<MISSING-{category}>"]))
                
                # Dodaj tokeny wstawionej encji
                current_conll_entry.extend(tokenize_and_tag(value, value, category))
        
        # Zapisz linie CoNLL dla bie≈ºƒÖcego zdania
        for token, tag in current_conll_entry:
            all_conll_lines.append(f"{token}\t{tag}")
            
        # Dodaj pustƒÖ liniƒô oddzielajƒÖcƒÖ zdania (wymagane w formacie CoNLL)
        all_conll_lines.append("")

    return all_conll_lines

# --- G≈Ç√≥wna funkcja ---

if __name__ == "__main__":
    values_by_cat, templates = load_data()
    
    if values_by_cat and templates:
        # Obliczenie docelowej liczby
        target_records = len(templates) * RECORDS_PER_TEMPLATE
        
        print(f"Za≈Çadowano {len(templates)} szablon√≥w i {len(values_by_cat)} kategorii warto≈õci.")
        print(f"Ustawiono, ≈ºe ka≈ºdy szablon zostanie u≈ºyty {RECORDS_PER_TEMPLATE} razy. Docelowy zbi√≥r: {target_records} rekord√≥w.")
        
        all_conll_output_lines = []
        
        # KLUCZOWA ZMIANA: Pƒôtla wielokrotnego generowania
        for i in range(RECORDS_PER_TEMPLATE):
            print(f"Generacja: {i + 1}/{RECORDS_PER_TEMPLATE}...")
            # 1. Generowanie danych CoNLL (za ka≈ºdym razem losowane sƒÖ nowe warto≈õci)
            conll_output_lines = generate_conll(templates, values_by_cat)
            all_conll_output_lines.extend(conll_output_lines)

        # 2. Zapis do pliku
        try:
            # Zapisujemy wszystkie wygenerowane linie
            with open(OUTPUT_CONLL_FILE, "w", encoding="utf-8") as f:
                f.write("\n".join(all_conll_output_lines))
                
            generated_sentences = len(templates) * RECORDS_PER_TEMPLATE
            print(f"\n‚úÖ Pomy≈õlnie zapisano {generated_sentences} zda≈Ñ (szablon√≥w) do {OUTPUT_CONLL_FILE}")
            
        except Exception as e:
            print(f"B≈ÇƒÖd podczas zapisu pliku: {e}")